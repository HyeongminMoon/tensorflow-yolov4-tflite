{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce63522-361d-4b23-bbb5-00c6a4efa281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import app, flags, logging\n",
    "from absl.flags import FLAGS\n",
    "import absl\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from core.yolov4 import YOLO, decode, compute_loss, decode_train\n",
    "from core.dataset import Dataset\n",
    "from core.config import cfg\n",
    "import numpy as np\n",
    "from core import utils\n",
    "from core.utils import freeze_all, unfreeze_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d5e6661-0270-4e08-b6df-995aa498a9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x2685bdcf448>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flags = absl.app.flags\n",
    "# FLAGS = flags.FLAGS\n",
    "\n",
    "# absl.app.flags.DEFINE_string('f','','kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "552afd7e-d9e8-45c8-9812-30b059b0d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flags.DEFINE_string('model', 'yolov4', 'yolov4, yolov3')\n",
    "# flags.DEFINE_string('weights', './scripts/yolov4.weights', 'pretrained weights')\n",
    "# flags.DEFINE_boolean('tiny', False, 'yolo or yolo-tiny')\n",
    "\n",
    "FLAGS.model = 'yolov4'\n",
    "FLAGS.weights = './scripts/yolov4.weights'\n",
    "FLAGS.tiny = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a711093-4ea2-4902-843e-7b1f6246cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(_argv):\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "987298e4-c27c-43ad-b527-e96acb8b1c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1377847-096a-437f-a3ba-fe62c88ee50c",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnparsedFlagAccessError",
     "evalue": "Trying to access flag --model before flags were parsed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnparsedFlagAccessError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18560/3878692015.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\absl\\flags\\_flagvalues.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[1;31m# get too much noise.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnparsedFlagAccessError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnparsedFlagAccessError\u001b[0m: Trying to access flag --model before flags were parsed."
     ]
    }
   ],
   "source": [
    "FLAGS.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c260d650-87d2-48e5-bce8-cbc98ab994e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnparsedFlagAccessError",
     "evalue": "Trying to access flag --tiny before flags were parsed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnparsedFlagAccessError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18560/2906581615.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtestset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mB:\\jupyter\\tensorflow-yolov4-tflite\\core\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, FLAGS, is_training, dataset_type)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_type\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"converted_coco\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtiny\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtiny\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manchors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_CLASS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXYSCALE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\absl\\flags\\_flagvalues.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[1;31m# get too much noise.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnparsedFlagAccessError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnparsedFlagAccessError\u001b[0m: Trying to access flag --tiny before flags were parsed."
     ]
    }
   ],
   "source": [
    "trainset = Dataset(FLAGS, is_training=True)\n",
    "testset = Dataset(FLAGS, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d944381-6f33-443c-978d-a060ba3b2de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"./data/log\"\n",
    "isfreeze = False\n",
    "steps_per_epoch = len(trainset)\n",
    "first_stage_epochs = cfg.TRAIN.FISRT_STAGE_EPOCHS\n",
    "second_stage_epochs = cfg.TRAIN.SECOND_STAGE_EPOCHS\n",
    "global_steps = tf.Variable(1, trainable=False, dtype=tf.int64)\n",
    "warmup_steps = cfg.TRAIN.WARMUP_EPOCHS * steps_per_epoch\n",
    "total_steps = (first_stage_epochs + second_stage_epochs) * steps_per_epoch\n",
    "# train_steps = (first_stage_epochs + second_stage_epochs) * steps_per_period\n",
    "\n",
    "input_layer = tf.keras.layers.Input([cfg.TRAIN.INPUT_SIZE, cfg.TRAIN.INPUT_SIZE, 3])\n",
    "STRIDES, ANCHORS, NUM_CLASS, XYSCALE = utils.load_config(FLAGS)\n",
    "IOU_LOSS_THRESH = cfg.YOLO.IOU_LOSS_THRESH\n",
    "\n",
    "freeze_layers = utils.load_freeze_layer(FLAGS.model, FLAGS.tiny)\n",
    "\n",
    "feature_maps = YOLO(input_layer, NUM_CLASS, FLAGS.model, FLAGS.tiny)\n",
    "if FLAGS.tiny:\n",
    "    bbox_tensors = []\n",
    "    for i, fm in enumerate(feature_maps):\n",
    "        if i == 0:\n",
    "            bbox_tensor = decode_train(fm, cfg.TRAIN.INPUT_SIZE // 16, NUM_CLASS, STRIDES, ANCHORS, i, XYSCALE)\n",
    "        else:\n",
    "            bbox_tensor = decode_train(fm, cfg.TRAIN.INPUT_SIZE // 32, NUM_CLASS, STRIDES, ANCHORS, i, XYSCALE)\n",
    "        bbox_tensors.append(fm)\n",
    "        bbox_tensors.append(bbox_tensor)\n",
    "else:\n",
    "    bbox_tensors = []\n",
    "    for i, fm in enumerate(feature_maps):\n",
    "        if i == 0:\n",
    "            bbox_tensor = decode_train(fm, cfg.TRAIN.INPUT_SIZE // 8, NUM_CLASS, STRIDES, ANCHORS, i, XYSCALE)\n",
    "        elif i == 1:\n",
    "            bbox_tensor = decode_train(fm, cfg.TRAIN.INPUT_SIZE // 16, NUM_CLASS, STRIDES, ANCHORS, i, XYSCALE)\n",
    "        else:\n",
    "            bbox_tensor = decode_train(fm, cfg.TRAIN.INPUT_SIZE // 32, NUM_CLASS, STRIDES, ANCHORS, i, XYSCALE)\n",
    "        bbox_tensors.append(fm)\n",
    "        bbox_tensors.append(bbox_tensor)\n",
    "\n",
    "model = tf.keras.Model(input_layer, bbox_tensors)\n",
    "model.summary()\n",
    "\n",
    "if FLAGS.weights == None:\n",
    "    print(\"Training from scratch\")\n",
    "else:\n",
    "    if FLAGS.weights.split(\".\")[len(FLAGS.weights.split(\".\")) - 1] == \"weights\":\n",
    "        utils.load_weights(model, FLAGS.weights, FLAGS.model, FLAGS.tiny)\n",
    "    else:\n",
    "        model.load_weights(FLAGS.weights)\n",
    "    print('Restoring weights from: %s ... ' % FLAGS.weights)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "if os.path.exists(logdir): shutil.rmtree(logdir)\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# define training step function\n",
    "# @tf.function\n",
    "def train_step(image_data, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = model(image_data, training=True)\n",
    "        giou_loss = conf_loss = prob_loss = 0\n",
    "\n",
    "        # optimizing process\n",
    "        for i in range(len(freeze_layers)):\n",
    "            conv, pred = pred_result[i * 2], pred_result[i * 2 + 1]\n",
    "            loss_items = compute_loss(pred, conv, target[i][0], target[i][1], STRIDES=STRIDES, NUM_CLASS=NUM_CLASS, IOU_LOSS_THRESH=IOU_LOSS_THRESH, i=i)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "\n",
    "        gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        tf.print(\"=> STEP %4d/%4d   lr: %.6f   giou_loss: %4.2f   conf_loss: %4.2f   \"\n",
    "                 \"prob_loss: %4.2f   total_loss: %4.2f\" % (global_steps, total_steps, optimizer.lr.numpy(),\n",
    "                                                           giou_loss, conf_loss,\n",
    "                                                           prob_loss, total_loss))\n",
    "        # update learning rate\n",
    "        global_steps.assign_add(1)\n",
    "        if global_steps < warmup_steps:\n",
    "            lr = global_steps / warmup_steps * cfg.TRAIN.LR_INIT\n",
    "        else:\n",
    "            lr = cfg.TRAIN.LR_END + 0.5 * (cfg.TRAIN.LR_INIT - cfg.TRAIN.LR_END) * (\n",
    "                (1 + tf.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * np.pi))\n",
    "            )\n",
    "        optimizer.lr.assign(lr.numpy())\n",
    "\n",
    "        # writing summary data\n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar(\"lr\", optimizer.lr, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/total_loss\", total_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/giou_loss\", giou_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/conf_loss\", conf_loss, step=global_steps)\n",
    "            tf.summary.scalar(\"loss/prob_loss\", prob_loss, step=global_steps)\n",
    "        writer.flush()\n",
    "def test_step(image_data, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = model(image_data, training=True)\n",
    "        giou_loss = conf_loss = prob_loss = 0\n",
    "\n",
    "        # optimizing process\n",
    "        for i in range(len(freeze_layers)):\n",
    "            conv, pred = pred_result[i * 2], pred_result[i * 2 + 1]\n",
    "            loss_items = compute_loss(pred, conv, target[i][0], target[i][1], STRIDES=STRIDES, NUM_CLASS=NUM_CLASS, IOU_LOSS_THRESH=IOU_LOSS_THRESH, i=i)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "\n",
    "        tf.print(\"=> TEST STEP %4d   giou_loss: %4.2f   conf_loss: %4.2f   \"\n",
    "                 \"prob_loss: %4.2f   total_loss: %4.2f\" % (global_steps, giou_loss, conf_loss,\n",
    "                                                           prob_loss, total_loss))\n",
    "\n",
    "for epoch in range(first_stage_epochs + second_stage_epochs):\n",
    "    if epoch < first_stage_epochs:\n",
    "        if not isfreeze:\n",
    "            isfreeze = True\n",
    "            for name in freeze_layers:\n",
    "                freeze = model.get_layer(name)\n",
    "                freeze_all(freeze)\n",
    "    elif epoch >= first_stage_epochs:\n",
    "        if isfreeze:\n",
    "            isfreeze = False\n",
    "            for name in freeze_layers:\n",
    "                freeze = model.get_layer(name)\n",
    "                unfreeze_all(freeze)\n",
    "    for image_data, target in trainset:\n",
    "        train_step(image_data, target)\n",
    "    for image_data, target in testset:\n",
    "        test_step(image_data, target)\n",
    "    model.save_weights(\"./checkpoints/yolov4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dce3023-7705-4700-b261-cc98eaf41ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alsologtostderr',\n",
       " 'log_dir',\n",
       " 'logger_levels',\n",
       " 'logtostderr',\n",
       " 'model',\n",
       " 'only_check_args',\n",
       " 'op_conversion_fallback_to_while_loop',\n",
       " 'pdb',\n",
       " 'pdb_post_mortem',\n",
       " 'profile_file',\n",
       " 'run_with_pdb',\n",
       " 'run_with_profiling',\n",
       " 'runtime_oom_exit',\n",
       " 'showprefixforinfo',\n",
       " 'stderrthreshold',\n",
       " 'test_random_seed',\n",
       " 'test_randomize_ordering_seed',\n",
       " 'test_srcdir',\n",
       " 'test_tmpdir',\n",
       " 'tiny',\n",
       " 'use_cprofile_for_profiling',\n",
       " 'v',\n",
       " 'verbosity',\n",
       " 'weights',\n",
       " 'xml_output_file']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        app.run(main)\n",
    "    except SystemExit:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b60def-1cfc-462e-b4d0-4c804d7c157a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow24",
   "language": "python",
   "name": "tensorflow24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
